% Brett
\chapter{Experience with Kokkos}
\section{Performance}
Since Kokkos uses Cuda and OpenMP as a backend to achieve faster performance, we
chose to do some testing to confirm that Kokkos performs as well as these two
solutions. If Kokkos performed worse then Cuda or OpenMP, then programmers might
prefer these other solutions instead.  Fortunately, we found that Kokkos matches
the performance of Cuda and OpenMP in almost all cases.  The rest of this
section will describe our strategy for testing the performance of Kokkos
compared to Cuda and OpenMP, present graphs showing the differences observed,
and analyze the graphs.

In order to compare Kokkos, Cuda, and OpenMP, we wrote algorithmically
equivalent code using all three paradigms (using the same data layout and memory
access pattern) and recorded the runtime of each version.  To reduce noise in
the timing data, we repeated the same calculations five times and used the
average time.

Note that because we were unsure how Kokkos implements the team\_reduce()
function, we could not write a matching Cuda reduction.  Based on our project
priorities, we chose not to pursue this further.

These graphs present some of the performance differences and similarities of
Kokkos, Cuda, and OpenMP. Figure~\ref{fig:ContractDataDataScalar Kokkos
performance comparison} shows the raw times of Kokkos Cuda, Cuda, Kokkos OpenMP,
and OpenMP for ContractDataDataScalar.

\begin{figure}[!ht]
{\includegraphics[scale=.4]{CDDS_RawTimes_2d_largestSize_Comparison.pdf}}
\caption[ContractDataDataScalar Kokkos performance comparison]{
    Performance of Kokkos Cuda, Cuda, Kokkos OpenMP,
and OpenMP for ContractDataDataScalar with a memory size of 1 GB.}
\label{fig:ContractDataDataScalar Kokkos performance comparison}
\end{figure}

In this graph, the y-axis is time in seconds, so closer to zero is better. The
x-axis plots different contraction sizes.  Here, Kokkos OpenMP and OpenMP are
almost perfectly overlapping. We are not quite sure why they are not perfectly
overlapping, but it appears too consistent to be random noise. However, the
difference is small enough as to be fairly insignificant. 

Kokkos Cuda, however, shows major differences compared to Cuda. The two perform
identically for the smaller problems but diverge by a significant amount for
bigger problems. This trend exists because Kokkos launches a different number of
blocks compared Cuda; Kokkos launches fewer blocks, with the intention of
reusing them.  We believe this doesn't affect small problem sizes because such
problems require fewer blocks than the large problem sizes, so both Kokkos and
Cuda launch enough blocks.  However, there is clearly a difference in the bigger
problem sizes. 

Figure~\ref{fig:cffscomparison} shows ContractFieldFieldScalar with the slicing
technique (which uses shared memory) for both Kokkos Cuda and Cuda.  It also
includes the flat parallel algorithm in both Kokkos Cuda and Cuda.

\begin{figure}[!ht]
{\includegraphics[scale=.4]{CFFS_RawTimes_2d_largest_Comparison.pdf}}
\caption[ContractFieldFieldScalar Kokkos performance comparison]{
    Performance of the ``slicing'' nested parallelism approach.}
\label{fig:cffscomparison}
\end{figure}

In Figure~\ref{fig:cffscomparison}, the Cuda slicing performance is almost
identical to the Kokkos slicing performance. This shows that Kokkos's use of
shared memory matches that of Cuda.

Overall, most of our graphs show that Kokkos performs almost identically to Cuda
and to OpenMP.  We therefore accepted that Kokkos is not adding any major
overhead. There may be slight differences due to optimization choices, but
Kokkos performs similarly to the other multithreading solutions.

\section{Code Snippets}
Another major factor that plays into whether programmers will use a language,
feature, or library is code complexity and ease of coding. Thus, we also
investigated the usability, readability, and intuitiveness of Kokkos compared to
Cuda and OpenMP.

Parallelizing code with Kokkosis significantly more complex than doing the same
with OpenMP.  However, OpenMP is considerably less flexible than Kokkos; it
works only on the CPU, and does not generalize to the GPU.  Therefore, in the
case of code that needs only to run on the CPU, we would strongly advise OpenMP
because of its simplicity.  However, that is not the niche that Kokkos is trying
to fill. 

Cuda, however, requires similar amounts of code to Kokkos.  The code snippets
presented will point out the differences and similarities directly.  First, we
will show the data setup step of moving data onto the GPU, and then move to
comparing and contrasting the Cuda kernel and the Kokkos functor.

Figure~\ref{lst:ContractFieldFieldScalar Cuda Data Setup} shows the setup of the data on the GPU for Cuda.

\begin{figure}[!htb]
	\begin{lstlisting}
float * dev_leftDataArray;

cudaMalloc((void **) &dev_leftDataArray, 
	numContractions * numLeftFields * numPoints * 
	sizeof(float));
	
cudaMemcpy(dev_leftDataArray, &leftDataArray[0], 
	numContractions * numLeftFields * numPoints * sizeof(float), 
	cudaMemcpyHostToDevice);
	\end{lstlisting}

\caption{Code from Cuda \texttt{ContractFieldFieldScalar}
\label{lst:ContractFieldFieldScalar Cuda Data Setup}}
\end{figure}

There are three steps in the process: declaring a pointer to the data on the
CPU, allocating an array with the correct size on the GPU, then copying the data
over to the GPU from CPU (host) memory. This process is relatively simple and
self-explanatory.

Equivalent Kokkos code is shown in Figure~\ref{lst:ContractFieldFieldScalar
Kokkos Cuda Data Setup}

\begin{figure}[!htb]
	\begin{lstlisting}
typedef Kokkos::Cuda	DeviceType;
typedef Kokkos::View<float***, Kokkos::LayoutRight, DeviceType>
	ContractionData;
typedef typename ContractionData::HostMirror
	ContractionData_Host;

ContractionData dev_ContractData_Left("left_data",
	numContractions,
	numLeftFields,
	numPoints);

ContractionData_Host contractionData_Left = 
	Kokkos::create_mirror_view(dev_ContractData_Left);

for (int cell = 0; cell < numContractions; ++cell) {
	for (int lbf = 0; lbf < numLeftFields; ++lbf) {
		for (int qp = 0; qp < numLeftFields; ++qp) {
			contractionData_Left(cell, lbf, qp) = 
				contractionDataLeft[cell*numLeftFields*
				numPoints + lbf*numLeftFields + qp];
		}
	}
}
	\end{lstlisting}
\caption{Code from Kokkos Cuda \texttt{ContractFieldFieldScalar}
\label{lst:ContractFieldFieldScalar Kokkos Cuda Data Setup}}
\end{figure}

The Kokkos code first defines and creates the device and host Views. One of the
major differences compared to Cuda is that Kokkos uses its own data structure, a
View, instead of an array. This requires typedefs to define the
Views, but the small amount of extra work gives the
programmer much more control over the data. The control also comes at the cost
of having to use loops to copy the data into the host view instead of simply
copying raw memory.

However, this initial work is done only once, and allows the user to change the
layout of the data by simply changing the Kokkos::LayoutRight to
Kokkos::LayoutLeft.  This is useful in optimizing the data layout for both the
CPU and GPU. Overall, Kokkos is more verbose, but also more abstract, as it must
perform on both the CPU and GPU while Cuda only runs on the GPU. 

In a program's computational portion, Cuda uses a kernel while Kokkos uses a
functor.  However, for programs doing the same calculation, the parenthesis
operator in a Kokkos functor is almost an exact replica of the code in
the corresponding Cuda kernel. A Cuda kernel for ContractFieldFieldScalar is
shown in Figure~\ref{lst:ContractFieldFieldScalar Cuda kernel}.

\begin{figure}[htb]
	\begin{lstlisting}
__global__ void
cudaContractFieldFieldScalar_Flat_kernel(int numContractions,
	int numLeftFields,
	int numRightFields,
	int numPoints,
	float * __restrict__ dev_contractData_Left,
	float * __restrict__ dev_contractData_Right,
	float * dev_contractResults) {
	int contractionIndex = blockId.x * blockDim.x + threadIdx.x;
	while (contractionIndex < numContractions) {
		int myID = contractionIndex;
		int myCell = myID / (numLeftFields * numRightFields);
		int matrixIndex = myID % (numLeftFields * 
			numRightFields);
		int matrixRow = matrixIndex / numRightFields;
		int matrixCol = matrixIndex % numRightFields;
		
		// Calculate now to save computation later
		int lCell = myMatrix * numLeftFields * numPoints;
		int rCell = myMatrix * numRightFields * numPoints;
		int resultCell = myMatrix * numLeftFields * 
			numRightFields;
		
		float temp = 0;
		for (int qp =0; qp < contractionSize; qp++) {
			temp += dev_contractData_Left[lCell + 
				qp*numLeftFields + matrixRow] *
				dev_contractData_Right[rCell + 
				qp*numRightFields + matrixCol];
		}

		dev_contractResults[resultCell + 
			matrixRow * numRightFields + matrixCol] = 
				temp;
		
		contractionIndex += blockDim.x * gridDim.x;
	}
}
	
	\end{lstlisting}
\caption{Code from Cuda \texttt{ContractFieldFieldScalar}
\label{lst:ContractFieldFieldScalar Cuda kernel}}
\end{figure}

The parenthesis operator in the corresponding Kokkos functor is shown in
Figure~\ref{lst:ContractFieldFieldScalar Kokkos Cuda functor}.

\begin{figure}[htb]
	\begin{lstlisting}
KOKKOS_INLINE_FUNCTION
void operator() (const unsigned int elementIndex) const {
	int myID = elementIndex;
	int myCell = myID / (_numLeftFields * _numRightFields);
	int matrixIndex = myID % (_numLeftFields * _numRightFields);
	int matrixRow = matrixIndex / _numRightFields;
	int matrixCol = matrixIndex % _numRightFields;

	float temp = 0;
	for (int qp = 0; qp < _numPoints; qp++) {
		temp += _leftFields(myCell, qp, matrixRow) *
			_rightFields(myCell, qp, matrixCol);
	}
	_outputFields(myCell, matrixRow, matrixCol) = temp;
}
	\end{lstlisting}
\caption{Code from Kokkos Cuda \texttt{ContractFieldFieldScalar}
\label{lst:ContractFieldFieldScalar Kokkos Cuda functor}}
\end{figure}

Although there are more lines of code in the Kokkos functor (the code required to
declare the data members and the constructor), the Kokkos code is readable and
uncluttered.

The Kokkos functor does not need to calculate each thread's ID, while the Cuda
kernel has to use built-in constants such as blockId.x and  blockDim.x.
Indexing into a View is easier than indexing into a primitive C-style array,
especially when changing the layout of the data between LayoutLeft and
LayoutRight because no code changes need to occur in the functor.

\section{Personal Experience and Thoughts}
A task of the project was to document our experiences and thoughts about Kokkos,
including any issues that we have run into. Using new tools and learning new
syntax always has its tough periods, and getting used to Kokkos definitely had
some periods where we had no idea why a program was not compile or giving an
incorrect answer (especially in the beginning). But, after the initial learning
curve everything seemed to flow pretty well and make sense. 

Our team has never actually been responsible for installing Kokkos on our
machine, instead our liaison, Dr. Carter Edwards, did that for us. We are unable
to talk about the difficulties of downloading and installing the Kokkos library
on our machine, but we did have lots of trouble trying to compile and linking
against Kokkos originally. This was due to the fact that the same flags need to
be used when installing and compiling and linking against Kokkos. However, since
we did not install Kokkos ourselves and the documentation showing how to compile
and link against Kokkos used different flags than what were used during our
installation, we struggled for a while. Already this shows how Kokkos'
documentation is not as developed as one would like, which we will bring up
later, but it is understandable since Kokkos is new. 

Another obstacle that slowed us down when first using, is Kokkos' use of magic
words. For example, Kokkos requires the programmer to typedef Kokkos::Cuda or
Kokkos::OpenMP to device\_type, and it must be device\_type, not some other
name. Although the programmer can easily fix this, if the programmer is unaware
of this requirement it can cause a lot of hassle for a while. Every team member
ran into this at one time or another, but after a while we got used to it. When
following examples we learned to use the same names for the typedefs to make
sure that we did not run into another bug with the same nature. Once again
documentation would have helped in this situation, but there is not much
documentation, all we have are examples. On the bright side however, since we
were able to write all of our programs by simply following a few examples we
were able to see some of Kokkos' intuitiveness. Overall we really enjoy Kokkos'
philosophy and structure, which as mentioned before, is almost identical to
Intel's Thread Building Blocks (TBB). If you are familiar with TBB then learning
Kokkos is almost as simple as learning the syntax because they are in the same
paradigm. 

As previously mentioned, Kokkos has very little documentation. For any emerging
technology it is understandable that the creators choose to focus on
functionality instead of documentation, but the documentation needs to catch up
at some point. The examples were very helpful in getting us to our end goal of
working code, but examples are not as helpful in understanding what exactly is
happening, the meaning behind some portions of code, or why certain code is
necessary. Documentation would have also been helpful in seeing the default
values for functions and Views, as well as the other arguments that could have
been passed instead. There were many times we tried to use Google to find
information about Kokkos, but many times the information would point to
uncommented pieces of code, which is not always helpful in determining what is
going on. Overall we believe the documentation for Kokkos needs to improve in
order for new users to get past the initial learning curve and spread the word
about Kokkos. 

As a whole, our team's experience with Kokkos has been positive and see that it
offers a great alternative to other solutions that allow multithreading on
multiple architectures. A quick overview of the benefits of using Kokkos are:
Kokkos can create multithreaded code on the CPU, GPU, and XeonPhi, Views can
easily change the layout of the data, functors seem to keep the code cleaner and
more readable than Cuda's kernels, and the fact that Kokkos is a C++ library and
not a a new language adds simplicity. Some of the downsides and changes that we
believe would improve Kokkos include Views having more layouts than LayoutRight
and LayoutLeft, the use of magic words (or lack of using the right magic words)
can create bugs that are hard to find, the example code should include comments
to describe what is happening, and finally the documentation needs to improve.
However, extended use of Kokkos will solve most of these problems except for
Views being limited to two layout types, which is why our team had an overall
good experience with Kokkos.
